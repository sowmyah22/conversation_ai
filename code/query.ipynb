{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2025-05-06 18:47:37,615 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-05-06 18:47:37,926 - INFO - Loaded 50 articles into memory from Chroma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contextual RAG News Search Assistant\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 18:47:48,815 - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags \"HTTP/1.1 200 OK\"\n",
      "2025-05-06 18:47:48,817 - INFO - Ollama server is running\n",
      "2025-05-06 18:47:48,818 - INFO - Using intent-aware query: pakistan...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for relevant information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 18:47:50,246 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-05-06 18:47:50,263 - INFO - Query processing took 1.45 seconds\n",
      "2025-05-06 18:47:50,264 - INFO - Found 10 relevant articles for query: pakistan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing results to provide you with the best answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 19:06:47,105 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-05-06 19:06:47,151 - INFO - Response generation took 1136.89 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Based on the articles provided, here is a helpful response:\n",
      "\n",
      "India has taken a comprehensive strike against Pakistan following the deadly terror attack in Pahalgam that killed 26 people, most of them tourists [1]. The retaliatory measures include a blanket ban on all imports from Pakistan, suspension of mail exchanges, prohibition on Pakistani ships docking at Indian ports, and complete closure of Indian airspace to Pakistan-registered aircraft. This move has led to a significant escalation in diplomatic tensions between the two countries.\n",
      "\n",
      "It's worth noting that India's foreign exchange reserves currently stand at over $688 billion, while Pakistan's reserves have barely crossed $15 billion [2]. This massive gap highlights decades of different policy choices, governance structures, and economic strategies pursued by the two countries.\n",
      "\n",
      "In related news, Pakistani brides who entered India with short-term visas were denied visa extension and sent back to Pakistan [3]. The Ministry of Home Affairs rejected their request, citing standard procedures. The incident has raised concerns about the treatment of Pakistani nationals in India.\n",
      "\n",
      "The US has intervened to prevent any military conflict between India and Pakistan, urging both countries to de-escalate and pursue peace [4]. Secretary of State Marco Rubio spoke with Indian counterpart S Jaishankar, advocating for cooperation in investigating the attack and re-establishing direct communication. However, India has rejected Pakistan's proposal for a \"neutral\" probe into the mass killings at Pahalgam, dismissing it as a deception meant to distract attention from Islamabad's complicity [5].\n",
      "\n",
      "In other news, Virat Kohli has revealed why he quit T20 internationals after India's triumphant T20 World Cup campaign in 2024 [6]. He explained that the decision was taken purely understanding that there is a new set of players who are more than ready and they need time. The Indian cricket team has also seen changes with Rohit Sharma and Ravindra Jadeja announcing their retirements from the format.\n",
      "\n",
      "Sources:\n",
      "\n",
      "[1] \"Trade, water and airspace: How India put pressure on Pakistan after Pahalgam terror attack\" (https://timesofindia.indiatimes.com/india/trade-water-and-airspace-how-india-put-pressure-on-pakistan-after-pahalgam-terror-attack/articleshow/120870156.cms)\n",
      "\n",
      "[2] \"India's forex at $688 billion and counting: Where does Pakistan stand?\" (https://timesofindia.indiatimes.com/business/india-business/indias-forex-reserves-rise-to-688-13-billion-for-8th-straight-week/articleshow/120824163.cms)\n",
      "\n",
      "[3] \"Pakistani brides who entered India with short-term visas were denied visa extension and sent back to Pakistan\" (https://timesofindia.indiatimes.com/news/pakistani-brides-who-entered-india-with-short-term-visas-were-denied-visa-extension-and-sent-back-to-pakistan/articleshow/120826790.cms)\n",
      "\n",
      "[4] \"US intervenes to prevent military conflict between India and Pakistan, urges both countries to de-escalate and pursue peace\" (https://timesofindia.indiatimes.com/news/us-intervenes-to-prevent-military-conflict-between-india-and-pakistan-urges-both-countries-to-de-escalate-and-pursue-peace/articleshow/120826790.cms)\n",
      "\n",
      "[5] \"India rejects Pakistan's proposal for 'neutral' probe into Pahalgam terror attack\" (https://timesofindia.indiatimes.com/news/india-rejects-pakistans-proposal-for-neutral-probe-into-pahalgam-terror-attack/articleshow/120826790.cms)\n",
      "\n",
      "[6] \"Virat Kohli breaks silence, reveals why he quit T20 internationals after World Cup glory\" (https://timesofindia.indiatimes.com/sports/cricket/ipl/top-stories/virat-kohli-breaks-silence-reveals-why-he-quit-t20is-after-world-cup-glory/articleshow/120826790.cms)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "[Debug: Total processing time: 1138.36 seconds]\n",
      "\n",
      "Thank you for using News Search Assistant\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import ollama\n",
    "import time\n",
    "import json\n",
    "import chromadb\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "db_path = './chroma_db'  # Directory for Chroma persistent storage\n",
    "collection_name = 'articles'\n",
    "EMBEDDING_DIM = 768  # Dimension of nomic-embed-text embeddings\n",
    "\n",
    "# In-memory data stores\n",
    "articles_memory = []  # Stores all article data\n",
    "embeddings_memory = None  # Stores all embeddings as numpy array\n",
    "\n",
    "# Conversation history\n",
    "conversation_history = []\n",
    "MAX_HISTORY_LENGTH = 5  # Maximum number of recent exchanges to keep\n",
    "\n",
    "def load_articles_to_memory():\n",
    "    \"\"\"Load all articles and embeddings into memory from Chroma at startup\"\"\"\n",
    "    global articles_memory, embeddings_memory\n",
    "    \n",
    "    try:\n",
    "        # Initialize Chroma client\n",
    "        client = chromadb.PersistentClient(path=db_path)\n",
    "        collection = client.get_collection(collection_name)\n",
    "        \n",
    "        # Load all articles\n",
    "        results = collection.get(include=['embeddings', 'metadatas', 'documents'])\n",
    "        \n",
    "        # Prepare data structures\n",
    "        articles_memory = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for idx, (doc_id, embedding, metadata, document) in enumerate(\n",
    "            zip(results['ids'], results['embeddings'], results['metadatas'], results['documents'])\n",
    "        ):\n",
    "            article = {\n",
    "                'id': int(metadata.get('id', idx + 1)),\n",
    "                'title': metadata.get('title', 'Unknown'),\n",
    "                'url': metadata.get('url', 'Unknown'),\n",
    "                'full_text': document,\n",
    "                'publish_date': metadata.get('publish_date', 'Unknown'),\n",
    "                'keyword': metadata.get('keyword', 'Unknown'),\n",
    "                'author': metadata.get('author', 'Unknown'),\n",
    "                'article_keywords': json.loads(metadata.get('article_keywords', '[]'))\n",
    "            }\n",
    "            articles_memory.append(article)\n",
    "            embeddings_list.append(np.array(embedding, dtype=np.float32))\n",
    "        \n",
    "        embeddings_memory = np.array(embeddings_list)\n",
    "        logger.info(f\"Loaded {len(articles_memory)} articles into memory from Chroma\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load articles into memory: {e}\")\n",
    "        articles_memory = []\n",
    "        embeddings_memory = None\n",
    "\n",
    "# Initialize in-memory data at startup\n",
    "load_articles_to_memory()\n",
    "\n",
    "# Function to generate query embedding using Ollama\n",
    "def generate_query_embedding(query: str) -> Optional[np.ndarray]:\n",
    "    \"\"\"Generate embedding for a query using Ollama\"\"\"\n",
    "    try:\n",
    "        response = ollama.embeddings(model='nomic-embed-text', prompt=query)\n",
    "        embedding = np.array(response['embedding'], dtype=np.float32)\n",
    "        if len(embedding) != EMBEDDING_DIM:\n",
    "            logger.error(f\"Generated embedding has incorrect dimension: {len(embedding)}\")\n",
    "            return None\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating query embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_contextual_query(current_query: str) -> str:\n",
    "    \"\"\"Create an intent-aware contextual query by analyzing conversation history\"\"\"\n",
    "    global conversation_history\n",
    "    \n",
    "    if not conversation_history:\n",
    "        return current_query\n",
    "    \n",
    "    try:\n",
    "        history_context = \"\"\n",
    "        for i, (q, a) in enumerate(conversation_history[-MAX_HISTORY_LENGTH:]):\n",
    "            history_context += f\"User: {q}\\nAssistant: {a}\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"Given this conversation history and current query, please:\n",
    "1. Identify the main intent and key entities in the current query\n",
    "2. Determine if this query references previous conversation\n",
    "3. Create an enhanced search query that captures the full intent\n",
    "\n",
    "Conversation history:\n",
    "{history_context}\n",
    "\n",
    "Current query: {current_query}\n",
    "\n",
    "Output only the enhanced search query that best captures the user's intent with any implicit references resolved.\n",
    "\"\"\"\n",
    "        \n",
    "        response = ollama.generate(\n",
    "            model='llama3:8b',\n",
    "            prompt=prompt,\n",
    "            options={\n",
    "                'temperature': 0.1,\n",
    "                'top_p': 0.9,\n",
    "                'max_tokens': 200\n",
    "            }\n",
    "        )\n",
    "        enhanced_query = response['response'].strip()\n",
    "        \n",
    "        logger.info(f\"Generated intent-aware query: {enhanced_query[:100]}...\")\n",
    "        \n",
    "        if not enhanced_query or len(enhanced_query) < 5:\n",
    "            logger.warning(\"Intent extraction failed, using original query\")\n",
    "            return current_query\n",
    "            \n",
    "        return enhanced_query\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating intent-aware query: {e}\")\n",
    "        context_parts = []\n",
    "        for i, (q, _) in enumerate(conversation_history[-2:]):\n",
    "            context_parts.append(f\"Previous question: {q}\")\n",
    "        context_parts.append(f\"Current question: {current_query}\")\n",
    "        return \" \".join(context_parts)\n",
    "\n",
    "def query_embeddings(query: str, use_context: bool = True, top_k: int = 10) -> List[Dict]:\n",
    "    try:\n",
    "        ollama.list()\n",
    "        logger.info(\"Ollama server is running\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to connect to Ollama server: {e}\")\n",
    "        return []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if use_context:\n",
    "        contextual_query = get_contextual_query(query)\n",
    "        logger.info(f\"Using intent-aware query: {contextual_query[:100]}...\")\n",
    "    else:\n",
    "        contextual_query = query\n",
    "    \n",
    "    query_embedding = generate_query_embedding(contextual_query)\n",
    "    if query_embedding is None:\n",
    "        logger.error(\"Failed to generate query embedding\")\n",
    "        return []\n",
    "    \n",
    "    if not articles_memory:\n",
    "        logger.error(\"No articles available in memory\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Initialize Chroma client\n",
    "        client = chromadb.PersistentClient(path=db_path)\n",
    "        collection = client.get_collection(collection_name)\n",
    "        \n",
    "        # Query Chroma for top_k similar articles\n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k,\n",
    "            include=['metadatas', 'documents', 'distances']\n",
    "        )\n",
    "        \n",
    "        # Process results\n",
    "        output = []\n",
    "        for idx, (metadata, document, distance) in enumerate(\n",
    "            zip(results['metadatas'][0], results['documents'][0], results['distances'][0])\n",
    "        ):\n",
    "            article = {\n",
    "                'id': int(metadata.get('id', idx + 1)),\n",
    "                'title': metadata.get('title', 'Unknown'),\n",
    "                'url': metadata.get('url', 'Unknown'),\n",
    "                'full_text': document,\n",
    "                'publish_date': metadata.get('publish_date', 'Unknown'),\n",
    "                'keyword': metadata.get('keyword', 'Unknown'),\n",
    "                'author': metadata.get('author', 'Unknown'),\n",
    "                'article_keywords': json.loads(metadata.get('article_keywords', '[]')),\n",
    "                'similarity': 1 - distance  # Convert distance to similarity (cosine)\n",
    "            }\n",
    "            output.append(article)\n",
    "        \n",
    "        logger.info(f\"Query processing took {time.time() - start_time:.2f} seconds\")\n",
    "        logger.info(f\"Found {len(output)} relevant articles for query: {query}\")\n",
    "        return output\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error querying Chroma: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_response(query: str, articles: List[Dict]) -> Tuple[str, List[Dict]]:\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        context_parts = []\n",
    "        sources = []\n",
    "        \n",
    "        for i, a in enumerate(articles, 1):\n",
    "            title = a.get('title', 'No Title')\n",
    "            url = a.get('url', '#')\n",
    "            text = a.get('full_text', '')[:1500]\n",
    "            \n",
    "            sources.append({\n",
    "                'index': i,\n",
    "                'title': title,\n",
    "                'url': url\n",
    "            })\n",
    "            \n",
    "            context_parts.append(f\"Article {i}: {title}\\nSource: {url}\\n{text}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        history_context = \"\"\n",
    "        if conversation_history:\n",
    "            history_parts = []\n",
    "            for q, a in conversation_history[-3:]:\n",
    "                history_parts.append(f\"User: {q}\\nAssistant: {a}\")\n",
    "            history_context = \"Previous conversation:\\n\" + \"\\n\\n\".join(history_parts) + \"\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"You are a helpful assistant that provides information based on news articles. \n",
    "When referencing information, include citation numbers [1], [2], etc. that correspond to the source articles.\n",
    "Always reference your sources when providing facts. Always include URLs for your sources at the end of your response.\n",
    "\n",
    "{history_context}\n",
    "User: {query}\n",
    "\n",
    "Here are relevant articles to help you answer:\n",
    "{context}\n",
    "\n",
    "Provide a helpful response with proper citations using [1], [2], etc. and include a \"Sources:\" section at the end with the article titles and URLs.\n",
    "\"\"\"\n",
    "        \n",
    "        response = ollama.generate(\n",
    "            model='llama3:8b',\n",
    "            prompt=prompt,\n",
    "            options={\n",
    "                'temperature': 0.7,\n",
    "                'top_p': 0.9,\n",
    "                'max_tokens': 1500\n",
    "            }\n",
    "        )\n",
    "        response_text = response['response'].strip()\n",
    "        \n",
    "        logger.info(f\"Response generation took {time.time() - start_time:.2f} seconds\")\n",
    "        return response_text, sources\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating response: {str(e)}\")\n",
    "        query_words = query.lower().split()\n",
    "        \n",
    "        fallback = f\"I found some information that might help with your question about {' '.join(query_words[:3])}...\\n\\n\"\n",
    "        fallback += \"Here are some topics I can share information about:\\n\"\n",
    "        \n",
    "        for i, a in enumerate(articles[:5], 1):\n",
    "            title = a.get('title', 'No Topic')\n",
    "            url = a.get('url', '#')\n",
    "            fallback += f\"{i}. {title}\\n\"\n",
    "        \n",
    "        fallback += \"\\nSources:\\n\"\n",
    "        for i, a in enumerate(articles[:5], 1):\n",
    "            title = a.get('title', 'No Topic')\n",
    "            url = a.get('url', '#')\n",
    "            fallback += f\"[{i}] {title} - {url}\\n\"\n",
    "            \n",
    "        fallback += \"\\nWould you like to know more about any of these topics specifically?\"\n",
    "        return fallback, articles[:5]\n",
    "\n",
    "def ensure_citations(response: str, sources: List[Dict]) -> str:\n",
    "    \"\"\"Make sure the response includes citations and a Sources section\"\"\"\n",
    "    if not sources:\n",
    "        return response\n",
    "        \n",
    "    if \"Sources:\" not in response:\n",
    "        response += \"\\n\\nSources:\\n\"\n",
    "        for src in sources:\n",
    "            response += f\"[{src['index']}] {src['title']} - {src['url']}\\n\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "def main():\n",
    "    global conversation_history\n",
    "    \n",
    "    print(\"\\nContextual RAG News Search Assistant\\n\")\n",
    "    \n",
    "    if not articles_memory:\n",
    "        print(\"No articles loaded in memory. Please check Chroma database.\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nWhat would you like to know? (type 'exit' to quit): \")\n",
    "        if query.lower() in ['exit', 'quit', 'q']:\n",
    "            print(\"\\nThank you for using News Search Assistant\")\n",
    "            break\n",
    "            \n",
    "        total_start_time = time.time()\n",
    "        \n",
    "        print(\"\\nSearching for relevant information...\")\n",
    "        results = query_embeddings(query, use_context=True, top_k=10)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"I couldn't find any relevant articles for your question.\")\n",
    "            continue\n",
    "\n",
    "        print(\"Analyzing results to provide you with the best answer...\")\n",
    "        response, sources = generate_response(query, results)\n",
    "        response = ensure_citations(response, sources)\n",
    "        \n",
    "        print(\"\\n\" + \"─\" * 80)\n",
    "        print(response)\n",
    "        print(\"─\" * 80)\n",
    "        \n",
    "        conversation_history.append((query, response))\n",
    "        \n",
    "        if len(conversation_history) > MAX_HISTORY_LENGTH + 2:\n",
    "            conversation_history = conversation_history[-MAX_HISTORY_LENGTH - 2:]\n",
    "        \n",
    "        if logger.level <= logging.DEBUG:\n",
    "            print(f\"\\n[Debug: Total processing time: {time.time() - total_start_time:.2f} seconds]\")\n",
    "            \n",
    "        if query.lower() == \"clear history\":\n",
    "            conversation_history = []\n",
    "            print(\"Conversation history cleared.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.2.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from langchain) (2.11.4)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.40-cp39-cp39-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from langchain-community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from langchain-community) (1.26.4)\n",
      "Collecting chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 (from langchain-chroma)\n",
      "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from langchain-core) (4.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.34.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.0.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.15.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (14.0.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (8.5.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.45.3)\n",
      "Requirement already satisfied: anyio in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.16.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.39.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (5.29.3)\n",
      "Requirement already satisfied: sympy in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.18)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.53b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.30.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from importlib-resources->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.9.1)\n",
      "Requirement already satisfied: filelock in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2025.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/pranavi/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_chroma-0.2.3-py3-none-any.whl (11 kB)\n",
      "Downloading langchain_core-0.3.58-py3-none-any.whl (437 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp39-cp39-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading zstandard-0.23.0-cp39-cp39-macosx_10_9_x86_64.whl (788 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.7/788.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: zstandard, SQLAlchemy, mypy-extensions, marshmallow, jsonpointer, httpx-sse, async-timeout, typing-inspect, requests-toolbelt, jsonpatch, pydantic-settings, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community, chromadb, langchain-chroma\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 1.0.7\n",
      "    Uninstalling chromadb-1.0.7:\n",
      "      Successfully uninstalled chromadb-1.0.7\n",
      "Successfully installed SQLAlchemy-2.0.40 async-timeout-4.0.3 chromadb-0.6.3 dataclasses-json-0.6.7 httpx-sse-0.4.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.25 langchain-chroma-0.2.3 langchain-community-0.3.23 langchain-core-0.3.58 langchain-text-splitters-0.3.8 langsmith-0.3.42 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 requests-toolbelt-1.0.0 typing-inspect-0.9.0 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-chroma langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 11:13:40,648 - INFO - Connected to Chroma database with articles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contextual RAG News Search Assistant (Powered by LangChain)\n",
      "\n",
      "\n",
      "Searching for relevant information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 11:13:56,008 - INFO - Backing off send_request(...) for 0.8s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "The situation between India and Pakistan is escalating rapidly. The recent terrorist attack in Pahalgam, Jammu and Kashmir, has led to a significant deterioration in diplomatic relations between the two countries.\n",
      "\n",
      "Pakistan has threatened that any attempt to limit waters from the Indus would be regarded as \"an act of war\" [1]. This comes after India suspended the Indus Waters Treaty of 1960, which would severely reduce Pakistan's water supply [2].\n",
      "\n",
      "In response to the attack, India has demanded that Italy cut financing to Pakistan and also approached FATF (Financial Action Task Force) to include Pakistan in the grey list [3]. Additionally, India has begun work on hydroelectric projects to boost reservoir holding capacity at two dams in the Himalayan region of Kashmir [4].\n",
      "\n",
      "Pakistan's Prime Minister Shehbaz Sharif has said that the country is prepared \"for national defence\" after conducting a second missile test since the stand-off with India began [5]. The military conducted a training launch of a surface-to-surface ballistic missile with a range of 120 kilometres from its Fatah series [6].\n",
      "\n",
      "Tensions are also running high in Moradabad, where authorities have identified 22 Pakistani women living in the district on long-term visas who have given birth to 95 children in India. Most of the women came to India after marrying Indian men and continue to hold Pakistani citizenship while their children have acquired Indian nationality [7].\n",
      "\n",
      "Former Union Minister and BJP leader Anurag Thakur has warned that if Pakistan continues with anti-India operations, it would be \"wiped out\" [8]. He also criticized Congress leader Ajay Rai for his remark on the Rafale issue, saying that Congress itself has become a joke [9].\n",
      "\n",
      "Sources:\n",
      "\n",
      "[1] BBC - India threatens Pakistan's water supply over deadly Kashmir attack\n",
      "https://www.bbc.co.uk/programmes/w172zss0x7d1ws3\n",
      "\n",
      "[2] Economic Times - Pahalgam terror attack: India begins work on hydro projects after suspending Indus Waters Treaty with Pakistan\n",
      "https://economictimes.indiatimes.com/news/india/pahalgam-terror-attack-india-begins-work-on-hydro-projects-after-suspending-indus-waters-treaty-with-pakistan/articleshow/120889025.cms\n",
      "\n",
      "[3] Economic Times - India demands Italy cut financing to Pakistan after Pahalgam terror attack\n",
      "https://economictimes.indiatimes.com/news/new-updates/india-demands-italy-cut-financing-to-pakistan-after-pahalgam-terror-attack/articleshow/120898093.cms\n",
      "\n",
      "[4] Economic Times - India begins work on hydroelectric projects to boost reservoir holding capacity at two dams in Kashmir\n",
      "https://economictimes.indiatimes.com/news/india/pahalgam-terror-attack-india-begins-work-on-hydro-electric-projects-to-boost-reservoir-holding-capacity-at-two-dams-in-kashmir/articleshow/120889025.cms\n",
      "\n",
      "[5] Economic Times - Pakistan's PM says country is prepared for national defence after missile test\n",
      "https://economictimes.indiatimes.com/news/new-updates/pakistans-pm-says-country-is-prepared-for-national-defence-after-missile-test/articleshow/120897790.cms\n",
      "\n",
      "[6] Economic Times - Pakistan conducts second missile test since stand-off with India began\n",
      "https://economictimes.indiatimes.com/news/new-updates/pakistan-conducts-second-missile-test-since-standoff-with-india-began/articlesshow/120898093.cms\n",
      "\n",
      "[7] Economic Times - 22 Pakistani women living in Moradabad have given birth to 95 children in India\n",
      "https://economictimes.indiatimes.com/news/new-updates/22-pakistani-women-living-in-moradabad-have-given-birth-to-95-children-in-india/articlesshow/120898093.cms\n",
      "\n",
      "[8] Economic Times - Pakistan would be 'wiped out' if it continued anti-India operations: Anurag Thakur\n",
      "https://economictimes.indiatimes.com/news/politics-and-nation/pakistan-would-be-wiped-out-if-it-continued-anti-india-operations-anurag-thakur/articleshow/120897790.cms\n",
      "\n",
      "[9] Economic Times - Congress itself has become a joke: BJP's Anurag Thakur criticises Ajay Rai's 'nimbu mirchi on Rafale' remark\n",
      "https://economictimes.indiatimes.com/news/politics-and-nation/congress-itself-has-become-a-joke-bjps-anurag-thakur-criticises-ajay-rais-nimbu-mirchi-on-rafale-remark/articlesshow/120889438.cms\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "[Debug: Total processing time: 1659.44 seconds]\n",
      "\n",
      "Thank you for using News Search Assistant\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration \n",
    "db_path = './chroma_db'  # Directory for Chroma persistent storage\n",
    "collection_name = 'articles'\n",
    "EMBEDDING_MODEL = 'nomic-embed-text'\n",
    "LLM_MODEL = 'llama3:8b'\n",
    "MAX_HISTORY_LENGTH = 5  # Maximum number of recent exchanges to keep\n",
    "\n",
    "# Initialize LangChain components\n",
    "embedding_function = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory=db_path\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "llm = Ollama(model=LLM_MODEL, temperature=0.7, top_p=0.9, num_ctx=4096)\n",
    "\n",
    "# Set up conversation memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    max_token_limit=1000\n",
    ")\n",
    "\n",
    "# Define prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant that provides information based on news articles. \n",
    "When referencing information, include citation numbers [1], [2], etc. that correspond to the source articles.\n",
    "Always reference your sources when providing facts. Always include a Sources section at the end with the article titles and URLs.\n",
    "\n",
    "Here are relevant articles to help you answer:\n",
    "{context}\n",
    "\n",
    "Provide a helpful response with proper citations using [1], [2], etc. and include a \"Sources:\" section at the end with the article titles and URLs.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Format context documents for the prompt\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        metadata = doc.metadata\n",
    "        title = metadata.get('title', 'No Title')\n",
    "        url = metadata.get('url', '#')\n",
    "        text = doc.page_content[:1500]  # Limit text length\n",
    "        context_parts.append(f\"Article {i}: {title}\\nSource: {url}\\n{text}\")\n",
    "    return \"\\n\\n\".join(context_parts)\n",
    "\n",
    "# Extract sources for citation\n",
    "def extract_sources(docs: List[Document]) -> List[Dict]:\n",
    "    sources = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        metadata = doc.metadata\n",
    "        title = metadata.get('title', 'No Title')\n",
    "        url = metadata.get('url', '#')\n",
    "        sources.append({\n",
    "            'index': i,\n",
    "            'title': title,\n",
    "            'url': url\n",
    "        })\n",
    "    return sources\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain_with_sources(query: str):\n",
    "    # Retrieve relevant documents\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    # Format the context and extract sources\n",
    "    context = format_docs(docs)\n",
    "    sources = extract_sources(docs)\n",
    "    \n",
    "    # Get chat history\n",
    "    chat_history = memory.load_memory_variables({})[\"chat_history\"]\n",
    "    \n",
    "    # Run the LLM chain\n",
    "    response = prompt_template.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": query,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    \n",
    "    llm_response = llm.invoke(response.to_string())\n",
    "    \n",
    "    # Ensure response has proper citations\n",
    "    final_response = ensure_citations(llm_response, sources)\n",
    "    \n",
    "    return final_response, sources\n",
    "\n",
    "def ensure_citations(response: str, sources: List[Dict]) -> str:\n",
    "    \"\"\"Ensure the response includes a Sources section with citations.\"\"\"\n",
    "    if not sources:\n",
    "        return response\n",
    "    if \"Sources:\" not in response:\n",
    "        response += \"\\n\\nSources:\\n\"\n",
    "        for src in sources:\n",
    "            response += f\"[{src['index']}] {src['title']} - {src['url']}\\n\"\n",
    "    return response\n",
    "\n",
    "def main():\n",
    "    print(\"\\nContextual RAG News Search Assistant (Powered by LangChain)\\n\")\n",
    "\n",
    "    # Check if vectorstore has articles\n",
    "    try:\n",
    "        sample_docs = vectorstore.get(limit=1)\n",
    "        if not sample_docs['ids']:\n",
    "            print(\"No articles loaded in Chroma database. Please populate the database.\")\n",
    "            return\n",
    "        logger.info(f\"Connected to Chroma database with articles\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Chroma database: {e}\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        query = input(\"\\nWhat would you like to know? (type 'exit' to quit): \")\n",
    "        print(query)\n",
    "        if query.lower() in ['exit', 'quit', 'q']:\n",
    "            print(\"\\nThank you for using News Search Assistant\")\n",
    "            break\n",
    "\n",
    "        total_start_time = time.time()\n",
    "        print(\"\\nSearching for relevant information...\")\n",
    "\n",
    "        try:\n",
    "            # Run the RAG chain\n",
    "            response, sources = rag_chain_with_sources(query)\n",
    "\n",
    "            # Save to conversation history\n",
    "            memory.save_context({\"question\": query}, {\"output\": response})\n",
    "\n",
    "            # Trim conversation history\n",
    "            history = memory.load_memory_variables({})[\"chat_history\"]\n",
    "            if len(history) > MAX_HISTORY_LENGTH * 2:  # Account for Human/AI pairs\n",
    "                memory.chat_memory.messages = history[-MAX_HISTORY_LENGTH * 2:]\n",
    "\n",
    "            print(\"\\n\" + \"─\" * 80)\n",
    "            print(response)\n",
    "            print(\"─\" * 80)\n",
    "\n",
    "            if logger.level <= logging.DEBUG:\n",
    "                print(f\"\\n[Debug: Total processing time: {time.time() - total_start_time:.2f} seconds]\")\n",
    "\n",
    "            if query.lower() == \"clear history\":\n",
    "                memory.clear()\n",
    "                print(\"Conversation history cleared.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing query: {e}\")\n",
    "            print(\"An error occurred while processing your query. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 20:58:53,925 - INFO - Successfully initialized Chroma vectorstore\n",
      "2025-05-07 20:58:53,953 - INFO - Connected to Chroma database with articles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contextual RAG News Search Assistant (Powered by LangChain)\n",
      "\n",
      "user query: ipl\n",
      "\n",
      "Searching for relevant information...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "I'm happy to help! However, it seems like you didn't ask a specific question or provide any context about what you're looking for. If you could provide more information or clarify your query, I'll do my best to assist you.\n",
      "\n",
      "In the meantime, here are some interesting articles from recent news sources:\n",
      "\n",
      "* \"We missed you': Rohit Sharma presents T20 World Cup winning ring to Mohammad Siraj\" [1]\n",
      "* \"India makes Chenab run dry, for now\" [2]\n",
      "* \"India demands Italy cut financing to Pakistan\" [3]\n",
      "* \"Delhi National Lok Adalat: Check date, token registration, eligibility, documents required to settle your traffic challans\" [4]\n",
      "* \"Why startup investors are eyeing sports teams\" [5]\n",
      "* \"Stock market update: Nifty IT index advances 0.28%\" [6]\n",
      "* \"Hyderabad: Miss World 2025 contestants to attend IPL match as part of pageant festivities\" [7]\n",
      "* \"CII backs board engagement for ethical AI\" [8]\n",
      "* \"IIT-Madras launches 5 courses in AI through SWAYAM Plus\" [9]\n",
      "\n",
      "Sources:\n",
      "\n",
      "[1] https://economictimes.indiatimes.com/news/sports/we-missed-you-rohit-sharma-presents-t20-world-cup-winning-ring-to-mohammad-siraj/articleshow/120884351.cms\n",
      "\n",
      "[2] https://economictimes.indiatimes.com/news/politics-and-government/india-makes-chenab-run-dry-for-now/articleshow/120877121.cms\n",
      "\n",
      "[3] https://economictimes.indiatimes.com/news/international-india-demands-italy-cut-financing-to-pakistan/articleshow/120883441.cms\n",
      "\n",
      "[4] https://economictimes.indiatimes.com/markets/stocks/stock-watch/delhi-national-lok-adalat-check-date-token-registration-eligibility-documents-required-to-settle-your-traffic-challans/articleshow/120887321.cms\n",
      "\n",
      "[5] https://economictimes.indiatimes.com/news/business/why-startup-investors-are-eyeing-sports-teams/articleshow/120886141.cms\n",
      "\n",
      "[6] https://economictimes.indiatimes.com/markets/stocks/stock-watch/stock-market-update-nifty-it-index-advances-0-28/articleshow/120899425.cms\n",
      "\n",
      "[7] https://economictimes.indiatimes.com/news/india/hyderabad-miss-world-2025-contestants-to-attend-ipl-match-as-part-of-pageant-festivities/articlesshow/120888956.cms\n",
      "\n",
      "[8] https://economictimes.indiatimes.com/news/economy/policy/cii-backs-board-engagement-for-ethical-ai/articleshow/120878843.cms\n",
      "\n",
      "[9] https://economictimes.indiatimes.com/industry/services/education/iit-madras-launches-5-courses-in-ai-through-swayam-plus/articleshow/120894780.cms\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "[Debug: Total processing time: 1023.11 seconds]\n",
      "user query: exit\n",
      "\n",
      "Thank you for using News Search Assistant\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "db_path = './chroma_db'\n",
    "collection_name = 'articles'\n",
    "EMBEDDING_MODEL = 'nomic-embed-text'\n",
    "LLM_MODEL = 'llama3:8b'\n",
    "MAX_HISTORY_LENGTH = 5\n",
    "\n",
    "# Initialize Chroma vectorstore\n",
    "def initialize_vectorstore():\n",
    "    \"\"\"Initialize Chroma vectorstore with error handling.\"\"\"\n",
    "    try:\n",
    "        vectorstore = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embedding_function,\n",
    "            persist_directory=db_path\n",
    "        )\n",
    "        logger.info(\"Successfully initialized Chroma vectorstore\")\n",
    "        # Verify database has articles\n",
    "        sample_docs = vectorstore.get(limit=1)\n",
    "        if not sample_docs['ids']:\n",
    "            logger.warning(\"Chroma database is empty\")\n",
    "            return None\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize Chroma database: {e}\")\n",
    "        print(f\"Error initializing Chroma database: {e}\")\n",
    "        print(\"Attempting to reset and recreate collection...\")\n",
    "        try:\n",
    "            # Backup and reset database\n",
    "            if os.path.exists(db_path):\n",
    "                backup_path = f\"{db_path}.bak_{int(time.time())}\"\n",
    "                shutil.move(db_path, backup_path)\n",
    "                logger.info(f\"Backed up database to {backup_path}\")\n",
    "            vectorstore = Chroma(\n",
    "                collection_name=collection_name,\n",
    "                embedding_function=embedding_function,\n",
    "                persist_directory=db_path\n",
    "            )\n",
    "            logger.info(\"Recreated Chroma database and collection\")\n",
    "            # Check if new database has articles\n",
    "            sample_docs = vectorstore.get(limit=1)\n",
    "            if not sample_docs['ids']:\n",
    "                logger.warning(\"New Chroma database is empty\")\n",
    "                return None\n",
    "            return vectorstore\n",
    "        except Exception as e2:\n",
    "            logger.error(f\"Failed to recreate Chroma database: {e2}\")\n",
    "            return None\n",
    "\n",
    "# Initialize components\n",
    "embedding_function = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = initialize_vectorstore()\n",
    "\n",
    "# Only proceed with initializations if vectorstore is valid\n",
    "if vectorstore is None:\n",
    "    print(\"Failed to initialize Chroma database\")\n",
    "    exit(1)\n",
    "\n",
    "# Initialize remaining components\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "llm = Ollama(model=LLM_MODEL, temperature=0.7, top_p=0.9, num_ctx=4096)\n",
    "\n",
    "# Set up conversation memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    max_token_limit=1000\n",
    ")\n",
    "\n",
    "# Define prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant that provides information based on news articles. \n",
    "When referencing information, include citation numbers [1], [2], etc. that correspond to the source articles.\n",
    "Always reference your sources when providing facts. Always include a Sources section at the end with the article titles and URLs.\n",
    "\n",
    "Here are relevant articles to help you answer:\n",
    "{context}\n",
    "\n",
    "Provide a helpful response with proper citations using [1], [2], etc. and include a \"Sources:\" section at the end with the article titles and URLs.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Format context documents for the prompt\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        metadata = doc.metadata\n",
    "        title = metadata.get('title', 'No Title')\n",
    "        url = metadata.get('url', '#')\n",
    "        text = doc.page_content[:1500]\n",
    "        context_parts.append(f\"Article {i}: {title}\\nSource: {url}\\n{text}\")\n",
    "    return \"\\n\\n\".join(context_parts)\n",
    "\n",
    "# Extract sources for citation\n",
    "def extract_sources(docs: List[Document]) -> List[Dict]:\n",
    "    sources = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        metadata = doc.metadata\n",
    "        title = metadata.get('title', 'No Title')\n",
    "        url = metadata.get('url', '#')\n",
    "        sources.append({\n",
    "            'index': i,\n",
    "            'title': title,\n",
    "            'url': url\n",
    "        })\n",
    "    return sources\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain_with_sources(query: str):\n",
    "    # Retrieve relevant documents\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    # Format the context and extract sources\n",
    "    context = format_docs(docs)\n",
    "    sources = extract_sources(docs)\n",
    "    \n",
    "    # Get chat history\n",
    "    chat_history = memory.load_memory_variables({})[\"chat_history\"]\n",
    "    \n",
    "    # Run the LLM chain\n",
    "    response = prompt_template.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": query,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    \n",
    "    llm_response = llm.invoke(response.to_string())\n",
    "    \n",
    "    # Ensure response has proper citations\n",
    "    final_response = ensure_citations(llm_response, sources)\n",
    "    \n",
    "    return final_response, sources\n",
    "\n",
    "def ensure_citations(response: str, sources: List[Dict]) -> str:\n",
    "    \"\"\"Ensure the response includes a Sources section with citations.\"\"\"\n",
    "    if not sources:\n",
    "        return response\n",
    "    if \"Sources:\" not in response:\n",
    "        response += \"\\n\\nSources:\\n\"\n",
    "        for src in sources:\n",
    "            response += f\"[{src['index']}] {src['title']} - {src['url']}\\n\"\n",
    "    return response\n",
    "\n",
    "def main():\n",
    "    print(\"\\nContextual RAG News Search Assistant (Powered by LangChain)\\n\")\n",
    "\n",
    "    # Check if vectorstore has articles\n",
    "    try:\n",
    "        sample_docs = vectorstore.get(limit=1)\n",
    "        if not sample_docs['ids']:\n",
    "            print(\"No articles loaded in Chroma database. Please populate the database with articles.\")\n",
    "            print(\"Example: Use vectorstore.add_documents([Document(page_content='Text', metadata={'title': 'Title', 'url': 'URL'})])\")\n",
    "            print(\"If you have a script like 'articles_chroma.py', run it to populate the database, or restore a backup.\")\n",
    "            return\n",
    "        logger.info(f\"Connected to Chroma database with articles\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error accessing Chroma database: {e}\")\n",
    "        print(\"Error accessing Chroma database. Please ensure './chroma_db' is valid and populated.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        query = input(\"\\nWhat would you like to know? (type 'exit' to quit): \")\n",
    "        print(f\"user query: {query}\")\n",
    "        if query.lower() in ['exit', 'quit', 'q']:\n",
    "            print(\"\\nThank you for using News Search Assistant\")\n",
    "            break\n",
    "\n",
    "        total_start_time = time.time()\n",
    "        print(\"\\nSearching for relevant information...\")\n",
    "\n",
    "        try:\n",
    "            # Run the RAG chain\n",
    "            response, sources = rag_chain_with_sources(query)\n",
    "\n",
    "            # Save to conversation history\n",
    "            memory.save_context({\"question\": query}, {\"output\": response})\n",
    "\n",
    "            # Trim conversation history\n",
    "            history = memory.load_memory_variables({})[\"chat_history\"]\n",
    "            if len(history) > MAX_HISTORY_LENGTH * 2:\n",
    "                memory.chat_memory.messages = history[-MAX_HISTORY_LENGTH * 2:]\n",
    "\n",
    "            print(\"\\n\" + \"─\" * 80)\n",
    "            print(response)\n",
    "            print(\"─\" * 80)\n",
    "\n",
    "            if logger.level <= logging.DEBUG:\n",
    "                print(f\"\\n[Debug: Total processing time: {time.time() - total_start_time:.2f} seconds]\")\n",
    "\n",
    "            if query.lower() == \"clear history\":\n",
    "                memory.clear()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing query: {e}\")\n",
    "            print(\"An error occurred while processing your query. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
